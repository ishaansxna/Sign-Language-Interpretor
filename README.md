# ğŸ–ï¸ Sign Language Recognition Using Deep Learning

This project implements a **Sign Language Recognition System** using **Convolutional Neural Networks (CNNs)**. The model is trained to recognize American Sign Language (ASL) alphabet gestures from images and perform real-time classification using a webcam.

---

## ğŸš€ Features
- **Dataset Preprocessing**: Augments and prepares training, validation, and test datasets.
- **CNN Model Training**: Implements a deep learning model using TensorFlow/Keras.
- **Real-Time Prediction**: Uses OpenCV for real-time gesture recognition.
- **Alphabet Classification**: Recognizes ASL alphabets (`A-Z`), including special gestures (`del`, `nothing`, `space`).

---

## ğŸ“ Project Structure
```
ğŸ“‚ Sign Language Recognition
â”œâ”€â”€ ğŸ“„ preprocessdataset.py   # Prepares dataset and trains the model
â”œâ”€â”€ ğŸ“„ model.py               # Loads trained model and performs real-time prediction
â”œâ”€â”€ ğŸ“‚ asl_alphabet_train     # Training dataset directory (not included in repo)
â”œâ”€â”€ ğŸ“‚ asl_alphabet_test      # Test dataset directory (not included in repo)
â””â”€â”€ ğŸ“„ README.md              # Project documentation
```

---

## ğŸ“Š Dataset
- The model is trained on the **ASL Alphabet Dataset**, containing labeled images for each sign.
- Data augmentation techniques (rotation, width/height shifts, shear, zoom) are applied to improve robustness.

---

## ğŸ› ï¸ Setup & Installation
### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/yourusername/sign-language-recognition.git
cd sign-language-recognition
```

### 2ï¸âƒ£ Install Dependencies
```sh
pip install numpy tensorflow opencv-python
```

### 3ï¸âƒ£ Prepare Dataset
Place your dataset inside the appropriate directories:
```
ğŸ“‚ asl_alphabet_train/
ğŸ“‚ asl_alphabet_test/
```

### 4ï¸âƒ£ Train the Model
Run the preprocessing and training script:
```sh
python preprocessdataset.py
```

### 5ï¸âƒ£ Run Real-Time Prediction
Once the model is trained, test real-time sign detection using:
```sh
python model.py
```

---

## ğŸ§  Model Architecture
The CNN model consists of:
- **3 Convolutional Layers** with ReLU activation
- **Max-Pooling Layers** to reduce spatial dimensions
- **Flatten & Fully Connected Layers** with a dropout layer
- **Softmax Output Layer** for multi-class classification

---

## ğŸ“Œ How It Works
1. The camera captures a frame.
2. The image is **preprocessed** and **resized** to `(64x64)`.
3. The trained CNN model predicts the **most likely ASL sign**.
4. The predicted label is **displayed on the screen**.

---

## ğŸ¯ Future Improvements
- Support for **dynamic gestures** using RNN/LSTM.
- Improve accuracy with a **larger dataset**.
- Develop a **web/app interface** for better accessibility.

---

## ğŸ¤ Contributing
Feel free to **fork** this repository and submit a pull request for improvements!

---

## ğŸ“¬ Contact
- **GitHub:** [@ishaansxna](https://github.com/ishaansxna)  
- **LinkedIn:** [Ishaan Saxena](https://linkedin.com/in/ishaan-saxena-21942b277)  
- **Email:** [ishaansaxena2022@gmail.com](mailto:ishaansaxena2022@gmail.com)  

---

ğŸ“ **Note**: This project is built for educational purposes and can be improved further with advanced models.
```
